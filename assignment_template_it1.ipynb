{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a716389a-e46c-4e15-b473-b40d7c79a1d3",
   "metadata": {},
   "source": [
    "##### Instructions\n",
    "- Keep the original structure, you may add additional code cells and/or mark-down cells for clarity, legibility and/or structure.\n",
    "- Add the required descriptions, explanations, justifications to the mark-down cells. You can find more mark-down tips & tricks online, for example [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) and [here](https://www.ibm.com/docs/en/watson-studio-local/1.2.3?topic=notebooks-markdown-jupyter-cheatsheet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b017957-b9de-4e04-8dad-d90e9bea213d",
   "metadata": {},
   "source": [
    "# EXAM03: Data Science Group Assignment - Iteration 1\n",
    "\n",
    "**Group name:** [Enter Group Number]\n",
    "\n",
    "**Student names & numbers:**\n",
    "* [Damian van der Sluis] - []\n",
    "* [Achraf El Azzouzi] - [101674]\n",
    "* [Saeed Alhasan] - []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e735319e-ed1e-45a0-a976-2aff38fd4180",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 0. Iteration setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79f6f7d-068b-4554-8d4e-c088a8909db4",
   "metadata": {},
   "source": [
    "**Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc780e8c-cba7-450e-b5d5-6b2445a11681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4cb004-acbc-4566-abd1-fc4d5345d47d",
   "metadata": {},
   "source": [
    "**Load dataset(s)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cffc45c-3fdb-4e7c-9e6a-cb6983a5d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ships_inventory_iter1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea875bf-f228-4c0f-b353-206a163ec75c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Business Understanding\n",
    "*Rubric: LO 6.4D (Reflection on Process)*\n",
    "\n",
    "**Situation description**\n",
    "\n",
    "*Describe the Nebula Brokerage pricing problem. Why is their current \"gut feeling\" approach a risk?.*\n",
    "\n",
    "**Business objective(s)**\n",
    "\n",
    "*Justify why a data-driven baseline is needed*\n",
    "\n",
    "**Data mining goal(s)**\n",
    "\n",
    "*Explain what type of modeling task this is and why.*\n",
    "\n",
    "**Success criteria**\n",
    "\n",
    "*Determine success criteria for this iteration (the benchmark)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a0831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd5f790-54b1-4ee4-838f-2e813e3513be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Data Understanding\n",
    "*Rubric: LO 7.3Q (Visuals) & LO 6.4C (Process)*\n",
    "\n",
    "**Data exploration**\n",
    "\n",
    "*Include summary statistics and descriptions of data types below. Describe your findings.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45f5251d-5aee-4b9f-8564-193785930d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ship_ID</th>\n",
       "      <th>Galactic_Credits</th>\n",
       "      <th>Model_Cycle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.688140e+05</td>\n",
       "      <td>368814.000000</td>\n",
       "      <td>361408.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.311485e+09</td>\n",
       "      <td>19453.536818</td>\n",
       "      <td>7511.264529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.381124e+06</td>\n",
       "      <td>15540.472943</td>\n",
       "      <td>9.078571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.301583e+09</td>\n",
       "      <td>501.000000</td>\n",
       "      <td>7400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.308105e+09</td>\n",
       "      <td>7950.000000</td>\n",
       "      <td>7508.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.312604e+09</td>\n",
       "      <td>15990.000000</td>\n",
       "      <td>7513.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.315245e+09</td>\n",
       "      <td>27990.000000</td>\n",
       "      <td>7517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.317101e+09</td>\n",
       "      <td>777777.000000</td>\n",
       "      <td>7522.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Ship_ID  Galactic_Credits    Model_Cycle\n",
       "count  3.688140e+05     368814.000000  361408.000000\n",
       "mean   7.311485e+09      19453.536818    7511.264529\n",
       "std    4.381124e+06      15540.472943       9.078571\n",
       "min    7.301583e+09        501.000000    7400.000000\n",
       "25%    7.308105e+09       7950.000000    7508.000000\n",
       "50%    7.312604e+09      15990.000000    7513.000000\n",
       "75%    7.315245e+09      27990.000000    7517.000000\n",
       "max    7.317101e+09     777777.000000    7522.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 368814 entries, 0 to 368813\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Ship_ID            368814 non-null  int64  \n",
      " 1   Galactic_Credits   368814 non-null  int64  \n",
      " 2   Model_Cycle        361408 non-null  float64\n",
      " 3   Ship_Manufacturer  368814 non-null  str    \n",
      " 4   Sector             368814 non-null  str    \n",
      "dtypes: float64(1), int64(2), str(2)\n",
      "memory usage: 14.1 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary statistics\n",
    "display(df.describe())\n",
    "\n",
    "# Data types and basic information\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ffd0a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dataset shape: 368814 rows and 5 columns'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(f\"Dataset shape: {df.shape[0]} rows and {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c341a94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96797443-654e-4a65-a9fa-84a8a3fbf741",
   "metadata": {},
   "source": [
    "**Visualizations and patterns**\n",
    "\n",
    "*Discover patterns in the data by creating visualizations. Create at least a histogram of Galactic_Credits. Describe your observations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb56161c-753c-412c-b95f-ce9b8bf1dc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Generate visualizations (e.g., scatter plots, histograms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65918398-cc3a-4986-8530-8e32b69681cc",
   "metadata": {},
   "source": [
    "**Data insights and data quality**\n",
    "* **Insights:** What are the key trends? What does the distribution look like? What does that mean? \n",
    "* **Quality issues:** Document missing values, duplicates, outliers, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69990a-91c8-48ff-bf04-8658c6e2e6a6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Data Preparation\n",
    "*Rubric: LO 6.4C (Data Science Steps)*\n",
    "\n",
    "**Cleaning and preprocessing**\n",
    "*Describe and justify steps taken (e.g., imputation, handling outliers, fixing other errors).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f186c7a-10d1-4808-9818-e14ab7d116b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE CELL: Data cleaning and preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9974d45f-a56b-4a13-b8e9-daf8ef5029bf",
   "metadata": {},
   "source": [
    "**Adjusting dataset (optional)**\n",
    "*If you adjusted the dataset for modeling in additional ways, describe that here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b7120d-8bad-4b78-84bf-d62c7d503aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL CODE CELL: Additional preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91a9873-64fa-4b76-b891-8ffd2e968728",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Modeling\n",
    "*Rubric: LO 6.4C (Data Science Steps)*\n",
    "\n",
    "**Model setup**\n",
    "\n",
    "We gebruiken een **mean baseline model** als benchmark voor het voorspellen van `Galactic_Credits`. Dit model voorspelt voor elk schip dezelfde waarde: het gemiddelde van de prijzen uit de training data.\n",
    "\n",
    "**Waarom dit model?**\n",
    "- Het is de simpelste mogelijke voorspelling\n",
    "- Het dient als referentiepunt (baseline) waartegen we toekomstige modellen vergelijken\n",
    "- Elk geavanceerder model moet beter presteren dan deze baseline om als nuttig te worden beschouwd\n",
    "\n",
    "**Aanpak:**\n",
    "1. De data wordt gesplitst in 80% training en 20% test data\n",
    "2. Het gemiddelde van `Galactic_Credits` uit de training set wordt berekend\n",
    "3. Dit gemiddelde (~19,449 credits) wordt gebruikt als voorspelling voor alle schepen in de test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf125517",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd902930-dbad-4e7a-854b-2b6a31774d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline prediction (mean of training set): 19449.24\n"
     ]
    }
   ],
   "source": [
    "# CODE CELL: Model training and setup code\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Define target variable\n",
    "target = 'Galactic_Credits'\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Baseline model: predict the mean of the training set\n",
    "baseline_prediction = y_train.mean()\n",
    "y_pred_baseline = np.full(len(y_test), baseline_prediction)\n",
    "\n",
    "print(f\"Baseline prediction (mean of training set): {baseline_prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e31d2ad-37e3-462e-87c0-feed5d13b6a7",
   "metadata": {},
   "source": [
    "**Testing and performance**\n",
    "\n",
    "Het baseline model is geëvalueerd op de test set (20% van de data) met de volgende metrics:\n",
    "\n",
    "| Metric | Waarde | Betekenis |\n",
    "|--------|--------|-----------|\n",
    "| **MAE** | ~11,639 | Gemiddeld wijkt de voorspelling ~11,639 credits af van de werkelijke prijs |\n",
    "| **MSE** | ~253,859,800 | Kwadratische fout - grote fouten worden zwaarder bestraft |\n",
    "| **RMSE** | ~15,933 | Wortel van MSE, interpreteerbaar in credits |\n",
    "| **R²** | ~0 | Model verklaart 0% van de variantie in prijzen |\n",
    "\n",
    "**Interpretatie:**\n",
    "- De MAE van ~11,639 credits betekent dat voorspellingen gemiddeld ~60% afwijken van de werkelijke prijs\n",
    "- R² ≈ 0 is verwacht: een model dat alleen het gemiddelde voorspelt verklaart per definitie geen variantie\n",
    "- Deze metrics vormen de **benchmark** die in volgende iteraties verbeterd moet worden\n",
    "\n",
    "Hieronder kun je de code hiervoor zien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc70ff-ca1d-4cfd-b9ef-e65c86a7a58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mean Absolute Error (MAE)</td>\n",
       "      <td>1.163901e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mean Squared Error (MSE)</td>\n",
       "      <td>2.538598e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Root Mean Squared Error (RMSE)</td>\n",
       "      <td>1.593298e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R² Score</td>\n",
       "      <td>-1.819410e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Metric         Value\n",
       "0       Mean Absolute Error (MAE)  1.163901e+04\n",
       "1        Mean Squared Error (MSE)  2.538598e+08\n",
       "2  Root Mean Squared Error (RMSE)  1.593298e+04\n",
       "3                        R² Score -1.819410e-06"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE CELL: Testing and evaluation code\n",
    "# Evaluate baseline model performance\n",
    "mae = mean_absolute_error(y_test, y_pred_baseline)\n",
    "mse = mean_squared_error(y_test, y_pred_baseline)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_baseline)\n",
    "\n",
    "# Display metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['Mean Absolute Error (MAE)', 'Mean Squared Error (MSE)', 'Root Mean Squared Error (RMSE)', 'R² Score'],\n",
    "    'Value': [mae, mse, rmse, r2]\n",
    "})\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1b7202-d834-4571-8ce0-b7c8944058fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Evaluation\n",
    "*Rubric: LO 6.4C (Results vs. Objectives)*\n",
    "\n",
    "**Assessment against succes criteria** \n",
    "*What is the difference between the metrics? What does this mean? Did you meet the goals set in the Business Understanding?*\n",
    "\n",
    "**Key findings and limitations**\n",
    "*What did you learn? What are the limitations of this current model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79c53c2-ca1c-4182-ab8a-1bc1ba693eaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6 Personal Contribution\n",
    "*Rubric: LO 7.3P (Equal Contribution)*\n",
    "\n",
    "| Student name | Contribution | Personal lessons learned |\n",
    "| :--- | :--- | :--- |\n",
    "| Damian van der Sluis | *Contribution description* | *Personal lessons learned this iteration* |\n",
    "| Saeed Alhasan | *Contribution description* | *Personal lessons learned this iteration* |\n",
    "| Achraf El Azzouzi | *Contribution description* | *Personal lessons learned this iteration* |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
